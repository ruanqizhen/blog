---
title: "古诗生成模型"
date: "2022-05-07"
---

去年学习语言模型时，我尝试了一个小练习，训练了一个生成古诗的模型。虽然这个项目已经搁置了一段时间，但回顾其中的实践与思考，仍有不少值得总结之处。

## 背景

### 为什么选择古诗作为实验对象？

选择古诗而非其他文体作为实验对象，原因在于古诗相较其他文体的生成难度相对较低，尤其对于机器学习模型而言。主要体现在以下几个方面：

1. **文本长度短，记忆力要求低**  
   文体的长度直接影响生成的难度。当前主流的语言模型“记忆力”有限，随着生成文字的增加，内容偏离主题的风险也随之提升。  
   一首古诗不过几十字，这种长度对个人电脑的训练能力十分友好。而像散文，通常篇幅在几百字以上，若要生成高质量的结果，则需要更强的硬件资源和分布式计算支持。至于小说，动辄数十万字，还需考虑情节铺垫和悬念回收等复杂结构，这对现阶段的技术而言仍是巨大的挑战。（但是可以预见，将来的模型可处理的文本长度会大幅增加，这些可能就不再是问题了。）

2. **训练数据丰富且无版权限制**  
   古诗作为历史文化遗产，其训练数据不仅数量丰富，而且大多不受版权限制。这一特性使得获取和使用数据的成本极低，为模型训练提供了良好的基础。

### 诗词的现状：从巅峰到小众

诗词曾是中华文化的瑰宝，尤其在唐宋时期达到辉煌的巅峰。然而，随着时代变迁，其社会影响力和受众群体逐渐式微，最终沦为一种小众爱好。其现状可以从以下几点观察：

1. **失去大众市场**  
   在唐宋之后，诗词逐渐退居二线，但由于科举制度的存在，写诗依然是士子必备的基本功。然而，现代社会中诗词的实际需求几乎消失，取而代之的是各种大众化的文艺形式，比如影视、音乐和网络文学。诗词不再具备广泛的市场需求。

2. **观众寥寥，创作者维艰**  
   任何文艺形式要兴盛，必然依赖大量广泛的观众群体。然而，今天的诗词圈正好相反：许多诗词网站依赖创作者支付会员费用维持运营，而不是通过吸引观众带来收益。写诗从一种创作行为变成了消费行为。这种缺乏观众支持的现状，也让新一代的创作者难以壮大。

3. **应用价值局限**  
   如今诗词的实际应用多局限于形式上的点缀——例如庆典活动中的背景装饰，甚至观众对这些诗词的质量关注甚少。相比古诗词的艺术价值，当代诗词的创作难以企及同样的高度，其鉴赏价值也因此受到限制。

### 语言生成模型的潜在应用

尽管诗词的应用价值有限，但语言生成模型在其他领域仍大有可为。以我的个人经验为例，工作中定期需要撰写总结、评语、心得等各类文档，这些任务虽繁琐，却遵循固定格式，具备一定的规律性。如果语言生成模型能够在这方面实现更高水平的自动化，将极大提高效率。若能获取相关训练数据，我非常愿意尝试这一方向的模型开发。

此外，拓展到更广泛的文艺创作需求，相较于文字生成，音乐生成或许更具市场潜力。比如，许多视频节目需要配乐，而大部分配乐需求并不涉及复杂的艺术创作。如果AI能够实现这一领域的批量化、定制化创作，无疑会是一个广阔的应用场景。


## 计算机作诗的各种算法

### 一、基于规则的写诗算法

早期的计算机解决问题时，大多遵循一种简单直接的思路：将解题规则逐步列出，再将其翻译成计算机可以执行的指令。这种方法在写诗领域也有过尝试，尤其是针对诗词中那些结构严谨、规则分明的特点。例如：

- **篇有定句，句有定字，字有定声，联有定对**：  
  五言绝句需四句，每句五字；平仄格律也有固定规律，例如首句平平平仄仄，则次句多为仄仄仄平平。  
- **押韵规则**：  
  若第二句以韵母“eng”结尾，则第四句通常也需押同一韵。

这些规则易于形式化，因而成为早期写诗程序最常采用的方法。然而，基于规则的算法产出的诗句却鲜有令人满意者。例如，这样的句子就出自规则生成的结果： “音挑山落但，下剩物拼贪。”这样的句子不但无法理解，也谈不上美感。

为何基于规则的写诗算法难以奏效？原因可归结为以下几点：

1. **诗意的复杂性远超规则本身**  
   写诗远非仅遵循表面格律规则即可，它还需兼顾以下层面：  
   - **词法和语法**：  
     句子必须符合语言使用习惯，比如“声音洪亮”可以接受，但“跑步洪亮”则不通顺。  
   - **自然规则**：  
     诗句需与常识吻合，例如“乌云密布”与“晴空万里”不应同时出现。  
   - **情感逻辑**：  
     诗中情感需符合人类共鸣，例如“大海”让人心胸开阔，而“落花”容易触发伤感。  
     
   这些层面的规则复杂且微妙，很多只能意会而难以言传。即便是明确的规则，逐字逐句罗列其所有约束条件也是一项极为繁重且几近不可能完成的任务。

2. **规则本身也需要灵活性**  
   优秀的诗歌并非一味遵循规则，而是懂得如何在恰当时机打破规则。例如：“白发三千丈”这一夸张的表达，完全无视自然界的真实情况，却以极强的画面感和情感力量成为传世佳句。由此可见，遵循规则是基础，但超越规则是艺术。

3. **有用的规则往往不可量化**  
   基于规则的写诗算法只能处理那些可量化的形式规则，而真正决定诗歌优劣的，是深植于人类经验、文化积淀和艺术直觉中的隐性规律。这些规律很难被精确描述，更难以转化为计算机可执行的指令。

正因如此，基于规则的算法在写诗领域难以突破，最终停滞不前。尽管它为后续的发展奠定了探索的基础，但也暴露了这种方法的局限性：仅靠规则，计算机难以触及诗歌的艺术核心。

以下是改进后的版本，增强了逻辑性、可读性和文采：

### 二、从规则到规律

计算机与人类在能力上存在显著互补：计算机能够以极快的速度生成大量符合规则的文字，而人类在从中挑选出最合适的表达时展现了远超计算机的直觉和审美能力。换句话说，计算机擅长的是“量”，而人类擅长的是“质”。然而，当你不明确告诉计算机如何挑选最佳结果时，它只能随机组合文字，产生的质量自然不容乐观。

一种看似简单的改进思路是不断添加更多规则，为计算机挑选出更合适的文字提供指导。然而，问题在于：

1. **规则的复杂性**  
   写诗涉及的规则过于繁多且细致，想要全面罗列几乎不可能。人类的直觉和经验虽能在某些情况下提供灵感，但要系统化地表达这些隐性规则，无论从数量还是复杂度来看，都是极大的挑战。

2. **规则的局限性**  
   规则是人为制定的，往往只提供方向性指导，无法涵盖所有细节问题。而且，规则本质上是动态的：前人制定规则，后人便可能通过创新打破规则。例如，“白发三千丈”这种夸张的表达，若完全依赖既定规则，很可能永远无法生成。

相比之下，**规律**是一种客观存在，深植于大量已有作品之中。这些规律有些是作者刻意为之，有些则是在创作中自然而然形成的。规律不仅超越了规则的局限性，还更贴近真实创作过程。想象一下，一个人学习写诗的历程：从掌握基本格律开始，到大量阅读经典作品，体会何为“好诗”，再到尝试借鉴这些特点，最终形成自己的风格。这种学习路径其实就是通过“发现规律”来指导创作。

#### 从统计中发现规律

利用统计学方法，我们可以从现有的诗词作品中提炼出一些显而易见的规律。例如：

1. **高频词的统计**  
   《全宋词》中的高频词包括“东风”“何处”“人间”“风流”“归去”“江南”“西湖”“斜阳”“明月”等。这些词因为使用频率高，往往容易被大众接受且令人感觉“顺眼”。如果计算机优先从这些高频词中选择，而非完全随机挑选，其生成的诗句就显得自然得多。例如，将这些高频词随机组合，便能得到这样的句子：  
   **“回首明月，悠悠心事空；西湖何事寂寞中，风吹斜阳匆匆。”**  
   虽非佳作，却不再令人别扭。

2. **词语的搭配规律**  
   仅靠高频词仍显不足，因为即便词语本身流行，搭配不当也可能产生极为拗口的句子，比如：“江南大漠凭栏鱼”。因此，还需引入词语搭配的统计规律。例如，“流水”常与“浮萍”“落花”“恋恋”“相随”等词搭配。如果诗句中已经选择了“流水”，后续用词便应优先从这些搭配中挑选。

3. **对仗与修辞的规律**  
   对仗是古诗中一项重要技巧。例如，“云对雨，雪对风；晚照对晴空。”通过总结这样的对仗规律，计算机可以更准确地生成符合古典风格的句子。此外，夸张、比喻、谐音等修辞手法也可以通过数据挖掘找到适当的应用场景。

#### 超越已有规律

尽管基于统计的规律挖掘能显著提升计算机作诗的能力，但它的潜力仍然受到研究者视野的限制。大多数规律总结工作是由缺乏创作经验的外行完成的，包括我在内，我并不擅长写诗。即便我们能提取出高频词、对仗结构和搭配习惯，也无法触及那些更为隐秘但至关重要的规律 - 比如何时使用特定的夸张手法能创造强烈的艺术冲击，或何种谐音梗能令人拍案叫绝。这些深层次规律往往超出人类的想象。

那么，我们能否进一步解放计算机的潜力？不仅让它总结规律，还能让它主动发现那些超出我们认知范围的隐性规律？让计算机不仅充当“辅助分析工具”，更成为“创作规则的研究者”，甚至在一定程度上超越我们的视野？答案或许正藏在深度学习和生成模型的潜力之中。


### 三、基于机器学习的写诗算法

“机器学习”，顾名思义，是让计算机通过学习从数据中自动归纳出知识，而非依赖人工设定规则。简单来说，研究者向计算机提供一个训练集，比如《唐诗三百首》，不需要明确告诉它学习的具体细节，只需让它通过数据中的模式自行学习，并根据这些知识生成输出。

虽然“机器学习”这一概念并不新鲜，它的历史可以追溯到几十年前，但近年来，由于算法改进和硬件性能的飞跃，其应用在自然语言处理领域取得了巨大的突破。在自然语言处理中，常见的任务包括分类（如垃圾邮件检测）、问答、摘要生成、翻译、对话生成等。尽管这些任务看似各异，它们实际上可以用统一的“文字生成”框架来解决。所谓文字生成，就是根据输入的“上文”生成合适的“下文”。例如：

- 输入是一封邮件的文本，生成的“下文”是“是垃圾邮件”或“不是垃圾邮件”，这就实现了垃圾邮件分类。  
- 输入一段中文，输出对应的英文，即实现翻译功能。  
- 输入一个上联，生成对应的下联，便完成了对联创作。  
- 输入一个标题，生成诗句，则解决了诗词生成问题。

#### 人工神经网络：从简单到复杂

对于简单的任务，例如垃圾邮件分类，可以用朴素贝叶斯分类器等传统算法解决，并且效果相当不错。然而，文字生成是一个极其复杂的问题，必须借助更先进的技术——**人工神经网络**。  

人工神经网络模仿生物大脑，通过大量“神经元”相互连接组成的网络进行学习和推理。它们能够通过训练数据学习复杂的模式，并基于所学内容生成输出。然而，复杂的人工神经网络内部往往呈现“黑箱”特征：人类难以直接理解它们具体学到了什么，但可以通过实验验证其效果。  

人工神经网络的发展从“小型”开始。当年我在学校做人工神经网络的作业时，仅仅设计了包含二十几个节点的小型网络。稍微复杂些的问题，可能需要几百个节点，也不过相当于蚯蚓的“大脑”规模。而文字生成问题则复杂得多，仅生成单词和短语通常需要成千上万个节点，生成完整句子需要更大的网络规模。我曾训练的诗词生成模型，节点数已达上亿。  

如今，在文字生成领域表现出色的模型如**GPT-3**，其参数（节点数）超过了1700亿个，规模已经超过人类大脑皮层中神经元的数量。然而，即使如此，人工神经网络的效率远不及人脑。尽管神经网络的规模仍在快速增长，预计短期内它们还无法真正达到人类创作的深度和灵感，尤其在涉及长篇叙事或复杂情感表达的领域，如小说创作。

#### 从数据到创作：机器学习的局限与改进

有了强大的机器学习能力，像我这样的诗词门外汉似乎也无需了解太多创作技巧，只需将现有的诗词交给模型，让它“学习”即可。然而，这样训练出的模型只能复制已有数据中的特性，难以超越其局限性。例如：

假设《唐诗三百首》中只有关于“牛”的诗句，却没有提到“羊”。模型可以轻松学会“牛吃草，牛挤奶”，并在创作中重复这些内容。但它很可能永远不会主动生成“羊吃草，羊挤奶”，尽管在人类看来，这种类比是显而易见的。这暴露了机器学习模型的局限性：它只会重复训练集中的模式，而缺乏人类直觉中那种跨领域的类比能力。

#### 引入预训练：突破训练集的局限

为克服上述问题，现代语言模型通常引入**预训练**机制。在正式训练模型生成诗词之前，先用更大、更广泛的语料库（例如维基百科）进行预训练，让模型学习普遍的世界知识和语言规律。通过这种方式，模型能够建立更全面的认知。例如，通过预训练，模型知道“牛”和“羊”都是食草动物，具有相似的生活习性。当进入诗词训练阶段时，即便训练集中只有“牛吃草”的诗句，模型也能推理出“羊吃草”这样的创作内容。

这种方法显著扩展了模型的创作潜力，使其不再局限于训练集中的内容，而是能够结合预训练知识进行更有创造力的生成。事实上，预训练的引入也是近年来大规模语言模型取得成功的重要原因之一。通过这种方式，机器不仅能够学习规则和规律，还能在一定程度上模拟人类的类比和联想，为写诗等创作任务注入更多灵感与可能性。


## 我做的练习模型

### 一、模型选择  

在开始练习之前，我先研究了一些公开的诗词生成模型。简单的LSTM（长短期记忆网络）或seq2seq（序列到序列）模型虽然在处理语言生成问题上有一定的表现，但生成的诗句通常缺乏自然流畅感。真正效果较好的模型，几乎都是近年来基于超大预训练模型（如BERT、GPT）训练而成的。我在GitHub上找到了一些例子，其中某些生成的诗句质量之高，甚至让我这个理科生都难以分辨是AI创作还是人类创作。

#### 模型大小与性能的权衡  

通常情况下，模型越大，生成效果越好。然而，模型规模越大，训练所需的时间和资源成本也随之增加。此外，不同的预训练模型在使用上也有差异：有些可以直接用于文本生成，而另一些则需要额外添加神经网络层进行调整。  

出于学习和练习的目的，我选择了GPT-2的小型模型。这种模型虽然在长文本生成方面可能稍显不足，但在诗词生成的场景中已经足够胜任。更重要的是，GPT-2可以直接进行文本生成，使用起来非常方便。

#### 成本与效率的现实考量  

尽管GPT-2的小型模型已经简化了训练和使用过程，但其成本仍然需要仔细权衡。以下是一些关键的成本和性能因素：  

1. **训练成本**  
   使用GPU进行模型训练可以显著提高速度。训练一个小型GPT-2模型通常需要一到两天时间，即使租用云端GPU，费用仍在可接受范围内。然而，对于长期部署和发布，GPU的成本可能成为一大障碍。

2. **预测性能**  
   使用CPU运行GPT-2模型进行预测时，每次生成大约需要十秒钟，这对于实时应用来说显得过慢。相比之下，使用GPU可以将预测时间缩短到十分之一甚至更少，但同时也显著增加了运行成本。

3. **云服务器成本**  
   当前云服务的价格差异较大。例如，仅使用CPU的云服务器，每年费用大约￥70；而配备GPU的服务器，每年费用则高达￥7000左右。这种成本差距直接影响到模型的实际部署选择。

综合考虑了性能和成本，我最终选择在本地用GPU完成短期训练任务，而在日常运行中依赖CPU。虽然这种配置可能牺牲了一些响应速度，但在预算限制内，仍然是较为平衡的方案。


### 二、训练集选取

在整个项目中，整理训练集是最耗时费力的一项工作。对于大多数机器学习项目来说，训练集通常是“越大越好”，但在诗词生成任务中并非如此。虽然古人创作了大量诗词，但真正流传至今、被认可为高水平作品的只是极少数。如果将质量参差不齐的诗词都纳入训练集，模型很可能学不到优秀的创作风格，反而会受到劣质样本的干扰。  

理想情况下，训练集应仅包含那些公认的高水平诗词。此外，过大的训练集还可能激励模型生成一些不常用的生僻字或词。这些词语若使用不当，会显著降低作品的可读性。而高频词汇如“风月”“山水”等，无论如何搭配，通常都能保证生成的诗句具有较好的流畅性和观感。

#### 数据集规模与主题覆盖  

小规模的高质量训练集虽然能够提升生成内容的质量，但其覆盖的主题往往较为有限。我目前使用的训练集相对较小，主要包括《千家诗》《唐诗三百首》以及一些我个人偏爱的诗词作品。这个数据集在常见的风花雪月题材上表现尚可，但在涉及未训练过的主题（如现代科技或建设类题材）时，生成效果明显不足。  

如果资源允许，可以采用更大的训练集，同时为不同质量的诗词样本分配权重。这样一来，高质量的作品可以对模型的训练产生更大的影响，提升整体生成效果。

#### 韵律与押韵  

诗词的合辙押韵是一项重要特性，但我在练习中并未对此进行专门处理。直接向程序添加人为指定的平仄、尾韵等规则并非最佳方案。事实上，许多流传千古的经典古诗在现代普通话语音体系下，已经不再完全押韵，或仅实现宽松的韵律要求。审美上，人们对这些诗词早已适应，因此过度强调押韵可能反而影响生成诗词的自然性与美感。

最优解是让模型通过学习数据集中的韵律信息，自主掌握如何生成自然的押韵诗句。然而，目前我的训练集中仅包含文字信息，缺乏音韵相关的标注。解决办法是将发音信息加入数据集。例如，将“风雨送悲声”扩展为“风feng1雨yu3送song4悲bei1声sheng1”。通过这种“字+拼音”的格式，模型可以学习到平仄与押韵的规律，从而提升生成的诗词在韵律上的自然性。

#### 扩展能力  

目前的训练集也未包含文字的书写信息，因此模型无法掌握诸如拆字对联等更复杂的诗词创作功能。如果将汉字的结构信息纳入数据集，例如通过图像表示文字的书写方式，或者将其抽象为偏旁部首的组合，模型就有可能学习到与汉字结构相关的创作技巧，从而实现更多元化的生成能力。


### 三、损失函数

在机器学习中，损失函数是衡量模型预测结果与真实值之间差异的指标。训练模型的本质就是不断调整模型参数，以最小化损失函数。我最初的尝试中，为了简化流程，使用了语言模型常用的默认损失函数——**交叉熵损失（Cross-Entropy Loss）**。

交叉熵损失主要衡量模型预测的词语概率分布与真实分布之间的差异。具体来说，对于一个给定的句子，模型会预测每个位置上出现各个词语的概率。交叉熵损失会惩罚模型预测的概率分布与真实分布之间的偏差。例如，如果真实句子中某个位置的词语是“明月”，而模型预测“清风”的概率很高，那么损失就会比较大。

然而，仅仅使用交叉熵损失进行训练，并不能很好地捕捉诗歌创作中的一些特有规律，例如押韵、对仗、意境等。这是因为交叉熵损失只关注词语层面的预测准确性，而忽略了诗歌的整体结构和艺术性。正如我之前提到的，一些规则，例如押韵和用词的丰富性，模型很难仅通过大量文本数据自行学习，尤其是在数据集规模有限的情况下。

为了解决这个问题，可以考虑引入一些额外的损失函数或修改训练策略，以显式地引导模型学习诗歌的特有规律：

1.  **韵律损失（Rhyme Loss）：** 可以通过计算生成诗句的韵脚与目标韵脚之间的差异来定义韵律损失。例如，可以使用编辑距离（Levenshtein Distance）或基于发音相似度的指标来衡量韵脚的相似程度。将韵律损失与交叉熵损失加权求和，可以促使模型生成更符合韵律要求的诗句。更进一步，可以考虑平仄格律，设计更精细的韵律损失函数。

2.  **对仗损失（Parallelism Loss）：** 对于律诗等讲究对仗的诗歌形式，可以设计对仗损失来衡量上下句之间的结构相似性和语义关联性。例如，可以计算上下句词向量的余弦相似度，或者使用句法分析等方法来比较句子的结构。

3.  **主题一致性损失（Topic Coherence Loss）：** 为了保证生成的诗歌围绕一个中心主题展开，可以引入主题一致性损失。例如，可以使用主题模型（如LDA）提取诗歌的主题向量，并计算生成诗句与主题向量之间的相似度。

4.  **词语多样性损失（Word Diversity Loss）：** 为了避免模型生成重复或单调的词语，可以引入词语多样性损失。例如，可以惩罚模型生成高频词或重复使用某个词语的行为。一种简单的方法是计算生成诗句中不同词语的数量，并将其作为损失函数的一部分。

除了修改损失函数，还可以通过调整训练数据来弥补模型学习的不足。例如，在训练集中尽量避免包含过多重复词语的诗句，或者人为地标注诗句的韵脚、对仗关系等信息，以帮助模型更好地学习这些规律。通过精心设计损失函数和训练数据，可以有效地提高模型生成诗歌的质量和艺术性。

### 四、训练时间

模型训练时间是一个重要的考量因素，它直接关系到开发效率和资源成本。正如我之前的经验，使用GPU进行训练可以显著提高速度，相比CPU训练，速度提升可达一到两个数量级。这主要是因为GPU拥有强大的并行计算能力，能够高效地处理神经网络中的大量矩阵运算。

训练时间的长短与多种因素相关，包括：

-   **模型大小：** 模型参数越多，训练所需的计算量越大，时间越长。
-   **数据集大小：** 数据量越大，模型需要学习的模式越多，训练时间也越长。
-   **硬件配置：** GPU的型号和数量、内存大小等都会影响训练速度。
-   **优化算法和超参数：** 不同的优化算法和超参数设置（如学习率、批次大小等）也会影响收敛速度。

在我最初的实验中，由于模型和数据集规模相对较小，使用GPU训练一两个小时就能取得不错的效果。然而，在这个阶段，模型偶尔会产生一些“莫名其妙”的结果，例如不符合语法规则的句子或意义不明的词语组合。这通常是由于模型尚未充分学习到语言的内在规律。

增加训练时间可以使模型更好地拟合训练数据，从而减少此类错误。然而，过长的训练时间也可能导致**过拟合（Overfitting）**，即模型过度学习了训练数据中的噪声和细节，而失去了泛化能力，导致在新的数据上表现不佳。此外，正如我个人的感受，过长的训练时间可能会使模型变得过于“规范”，从而削弱了预训练数据带来的“天马行空”的创造力。

这种现象可以用偏差-方差权衡（Bias-Variance Tradeoff）来解释。较短的训练时间可能导致模型偏差较大，即未能充分学习到训练数据中的规律；而过长的训练时间则可能导致模型方差较大，即对训练数据中的噪声过于敏感。理想的训练时间应该在偏差和方差之间取得平衡，使模型既能准确地捕捉数据中的规律，又能保持一定的泛化能力和创造力。

因此，确定最佳的训练时间需要进行仔细的实验和调优。一种常用的方法是使用**验证集（Validation Set）**来监控模型的训练过程。在每个训练周期结束后，使用验证集评估模型的性能，并根据验证集上的表现来调整训练参数和提前终止训练，以避免过拟合。

总之，训练时间的选择是一个需要在效率、泛化能力和创造力之间进行权衡的过程。通过合理的实验和调优，可以找到最佳的训练策略，使模型既能生成规范的诗句，又能保持一定的创造性和艺术性。


### 五、生成结果

对于任何生成模型而言，最终的评判标准都落实在其输出质量上。由于我并非诗词领域的专家，因此只进行一些最浅显的比较分析。

**1. 对联生成：展现一定的理解能力**

对联是对诗歌创作能力的初步考察。以“倦鸟无心归去”为上联，模型生成的下联“野花有意偷开”展现出一定的理解能力。“倦鸟”与“野花”构成意象上的对比，“无心”与“有意”形成情感上的反差，“归去”与“偷开”则在动作上呼应，整体对仗工整，意境也颇为和谐。虽然我并不认为模型真正“理解”了野花的“有意”，但它成功地捕捉到了训练数据中“野花”与“开放”、“烂漫”等意象的关联，并将其运用到对联生成中。

然而，模型也并非总是表现出色。例如，看到这一副生成的对联时，我差点一口老血喷到屏幕上：“千家百姓，共建和谐社会；三宫六院，同沾雨露春风”。这副对联虽然在形式上对仗工整，但内容上却显得格格不入。“和谐社会”是现代政治语境下的概念，“三宫六院”则是古代帝王生活的写照，两者在时空和语境上存在巨大的冲突。这表明模型在理解语境和常识方面仍然存在不足。

**2. 诗歌生成：空灵意境与主题缺失**

模型生成的诗歌在描绘自然景物方面表现出一定的优势，能够营造出空灵的意境，例如：

> 风卷残阳去，云敛暮雨收。身羁千里外，白发几时休。
> 故国关山隔，天涯岁月悠。相思无处寄，明月满西楼。

这首诗描绘了夕阳西下、暮雨初歇的景象，表达了漂泊天涯、思乡怀人的情感。诗句流畅自然，意境较为完整。

然而，模型生成的诗歌也暴露出一些问题：

*   **主题不够突出：** 虽然诗句描绘了景物和情感，但整体主题不够鲜明，缺乏深刻的内涵。
*   **情感表达较为单一：** 模型倾向于表达一些较为普遍的情感，例如思乡、忧愁等，而难以表达更复杂、更细腻的情感。
*   **缺乏个人风格：** 模型生成的诗歌虽然符合古典诗歌的格律和意境，但缺乏独特的个性和风格。

正如我之前所说，诗人一生的经历和情感都会融入到作品中，而模型缺乏人类的经历和情感，因此难以创作出具有深刻内涵和独特风格的诗歌。从某种意义上说，模型更擅长生成“空洞”的诗歌，即那些不需要具体内容支撑、以描景抒情为主的诗歌。但这并非完全是缺点。在某些场景下，例如商业宣传、节日祝福、对领导歌功颂德等，这种“空洞”的诗歌反而更受欢迎。

**3. 示例诗歌：展示生成能力**

以下是一些经过**挑选和改进**的，（模型本身还不没达到稳定生成高质量诗歌的水平）供读者参考：

> 城南雨过花含泪，陌上风来柳化烟。远客扶杖回首望，长亭别后共谁言。

> 晓日照野烟，春风拂青山。谁家新酿熟，香透小楼间。

> 潭清月冷影自长，山空竹瘦共疏凉。浮云过眼心如水，一任清风送晚香。

> 痒来无奈手频抓，愈搔愈烈乱如麻。世间欲念多如此，不动心时气自华。

> 太虚无色夜澄清，万象悠悠映远星。俗世尘埃皆是幻，心归净土自安宁。

> 一念不生即是禅，何劳经卷细研传。拈花微笑菩提意，明心见性自天然。

> 独住栖真境，岚烟锁竹扉。翠霭笼云舍，霜英点槿篱。
> 荷锄携月返，闭户焚香迟。醉卧松根石，蝶梦逐流溪。

> 《忆秦娥·春思》
> 飞花坠，纷纷一晌逐东风。逐东风，凝眸处，烟浦锁离愁。
> 鲛绡浥泪，淡匀红粉春衫冷；鸿雁声里，年年肠断，梦杳锦书凭。

这些例子展示了模型在生成诗歌方面的潜力。虽然仍然存在一些不足，但考虑到这只是一个个人练习项目，取得这样的结果已经相当不错。
